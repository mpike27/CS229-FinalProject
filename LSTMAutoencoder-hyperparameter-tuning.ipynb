{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------- Config.py ---------------------------#\n",
    "class Config:\n",
    "    TRAINSET_PATH = 'Data/Training2/'\n",
    "    MODEL_PATH = 'LSTMAutoEncoderModel'#\"model\" + str(1)\n",
    "    BATCH_SIZE = 3\n",
    "    EPOCHS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------- Imports --------------------------#\n",
    "from os import listdir\n",
    "from os.path import isfile, join, isdir\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import shelve\n",
    "import cv2\n",
    "from tensorflow.keras.layers import Conv2DTranspose, ConvLSTM2D, BatchNormalization, TimeDistributed, Conv2D, LayerNormalization\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import tensorflow\n",
    "import sys\n",
    "import Hyperparameters as hyp\n",
    "\n",
    "lr_opts = [0.0001, 0.001]\n",
    "decay_opts = [0.00001, 0.0001]\n",
    "eps_opts = [0.000001, 0.00001]\n",
    "num_filters_opts = [128, 64]\n",
    "kernel_size_opts = [11, 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------- AutoencoderParsing.py ---------------------------#\n",
    "def get_sliding_windows(frames_list, sequence_size):\n",
    "    \"\"\" For data augmenting purposes.\n",
    "    Parameters\n",
    "    ----------\n",
    "    frames_list : list\n",
    "        A list of sorted frames of shape hyp.FRAME_RES X hyp.FRAME_RES\n",
    "    sequence_size: int\n",
    "        The size of the lstm sequence\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        A list of clips , 20 frames each\n",
    "    \"\"\"\n",
    "    clips = []\n",
    " \n",
    "    for i in range(len(frames_list) - sequence_size):\n",
    "        clip = np.zeros(shape=(sequence_size, hyp.FRAME_RES, hyp.FRAME_RES, 1))\n",
    "        clip[:, :, :, 0] = frames_list[i : i + sequence_size]\n",
    "        clips.append(clip)\n",
    "    return np.array(clips)\n",
    "\n",
    "def getData(path):\n",
    "    data = []\n",
    "    for file in listdir(path):\n",
    "        if file[-3:] == \"npy\":\n",
    "            all_frames = np.load(path + file, allow_pickle=True)\n",
    "            data.extend(get_sliding_windows(frames_list=all_frames, sequence_size=hyp.SEQ_LEN))\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------- LSTM_Autoencoder_Model.py ---------------------------#\n",
    "def create_model(num_filters, kernel_size):\n",
    "    seq = Sequential()\n",
    "    seq.add(TimeDistributed(Conv2D(int(num_filters/2), kernel_size, strides=4, padding=\"same\"), batch_input_shape=(None, hyp.CLIP_LEN, hyp.FRAME_RES, hyp.FRAME_RES, 1)))\n",
    "    seq.add(LayerNormalization())\n",
    "    seq.add(TimeDistributed(Conv2D(int(num_filters/4), kernel_size - 6, strides=2, padding=\"same\")))\n",
    "    seq.add(LayerNormalization())\n",
    "    # # # # #\n",
    "    seq.add(ConvLSTM2D(int(num_filters/4), kernel_size - 8, padding=\"same\", return_sequences=True))\n",
    "    seq.add(LayerNormalization())\n",
    "    seq.add(ConvLSTM2D(int(num_filters/8), kernel_size - 8, padding=\"same\", return_sequences=True))\n",
    "    seq.add(LayerNormalization())\n",
    "    seq.add(ConvLSTM2D(int(num_filters/4), kernel_size - 8, padding=\"same\", return_sequences=True))\n",
    "    seq.add(LayerNormalization())\n",
    "    # # # # #\n",
    "    seq.add(TimeDistributed(Conv2DTranspose(int(num_filters/4), kernel_size - 6, strides=2, padding=\"same\")))\n",
    "    seq.add(LayerNormalization())\n",
    "    seq.add(TimeDistributed(Conv2DTranspose(int(num_filters/2), kernel_size, strides=4, padding=\"same\")))\n",
    "    seq.add(LayerNormalization())\n",
    "    seq.add(TimeDistributed(Conv2D(1, kernel_size, activation=\"sigmoid\", padding=\"same\")))\n",
    "#     print(seq.summary())\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training_set before split:  (45093, 10, 32, 32, 1)\n",
      "Shape of training_set:  (40583, 10, 32, 32, 1)\n",
      "Shape of validation_set:  (4510, 10, 32, 32, 1)\n",
      "Epoch 1/1000\n",
      "13528/13528 [==============================] - 3069s 227ms/step - loss: 13804.5645 - val_loss: 13786.9248\n",
      "Epoch 2/1000\n",
      " 3232/13528 [======>.......................] - ETA: 38:21 - loss: 13820.0391"
     ]
    }
   ],
   "source": [
    "#--------------------------- TrainAutoencoder.py ---------------------------#\n",
    "# training_set = ap.get_training_set()\n",
    "training_set = np.array(getData(Config.TRAINSET_PATH), copy=False)\n",
    "print(\"Shape of training_set before split: \", training_set.shape)\n",
    "training_set, validation_set, _, _ = train_test_split(training_set, training_set, test_size=0.1)\n",
    "print(\"Shape of training_set: \", training_set.shape)\n",
    "print(\"Shape of validation_set: \", validation_set.shape)\n",
    "best_lr, best_decay, best_eps, best_filters, best_kernels = 0, 0, 0, 0, 0\n",
    "val_loss = sys.maxsize\n",
    "for lr in lr_opts:\n",
    "    for decay in decay_opts:\n",
    "        for eps in eps_opts:\n",
    "            for num_filters in num_filters_opts:\n",
    "                for kernel_size in kernel_size_opts:\n",
    "                    model = create_model(num_filters, kernel_size)\n",
    "                    model.compile(loss='mse', optimizer=tensorflow.keras.optimizers.Adam(lr=lr, decay=decay, epsilon=eps))\n",
    "                    es = EarlyStopping(min_delta=eps, verbose=1, patience=3)\n",
    "                    history = model.fit(training_set, training_set, batch_size=Config.BATCH_SIZE, epochs=Config.EPOCHS,\n",
    "                                        validation_data=(validation_set, validation_set), callbacks=[es])\n",
    "                    final_val_loss = history.history['val_loss'].pop()\n",
    "                    print(\"val_loss: \", final_val_loss)\n",
    "                    print(f\"lr = {lr}\")\n",
    "                    print(f\"decay = {decay}\")\n",
    "                    print(f\"eps = {eps}\")\n",
    "                    print(f\"num_filters = {num_filters}\")\n",
    "                    print(f\"kernel_size = {kernel_size}\")\n",
    "                    if final_val_loss < val_loss:\n",
    "                        val_loss = final_val_loss\n",
    "                        best_lr = lr\n",
    "                        best_decay = decay\n",
    "                        best_eps = eps\n",
    "                        best_filters = num_filters\n",
    "                        best_kernels = kernel_size\n",
    "                        model.save(\"LSTM_Auto\")\n",
    "print('The optimal training hyperparams are:')\n",
    "print(f\"lr = {best_lr}\")\n",
    "print(f\"decay = {best_decay}\")\n",
    "print(f\"eps = {best_eps}\")\n",
    "print(f\"num_filters = {best_filters}\")\n",
    "print(f\"kernel_size = {best_kernels}\")\n",
    "print(f\"Best val_loss = {val_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
