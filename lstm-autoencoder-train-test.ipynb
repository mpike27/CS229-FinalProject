{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "6bc5107c-ff7b-4725-8f74-aa3cb4fc1958",
    "_uuid": "923cff4c-354f-42e6-8e85-aa3f5cfc610e",
    "execution": {
     "iopub.execute_input": "2020-11-15T12:13:25.891285Z",
     "iopub.status.busy": "2020-11-15T12:13:25.890617Z",
     "iopub.status.idle": "2020-11-15T12:13:34.876184Z",
     "shell.execute_reply": "2020-11-15T12:13:34.876640Z"
    },
    "papermill": {
     "duration": 9.001125,
     "end_time": "2020-11-15T12:13:34.876854",
     "exception": false,
     "start_time": "2020-11-15T12:13:25.875729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if \"GPU\" not in device_name:\n",
    "    print(\"GPU device not found\")\n",
    "print('Found GPU at: {}'.format(device_name))\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-15T12:13:34.900017Z",
     "iopub.status.busy": "2020-11-15T12:13:34.899267Z",
     "iopub.status.idle": "2020-11-15T12:13:35.166084Z",
     "shell.execute_reply": "2020-11-15T12:13:35.165326Z"
    },
    "papermill": {
     "duration": 0.282028,
     "end_time": "2020-11-15T12:13:35.166215",
     "exception": false,
     "start_time": "2020-11-15T12:13:34.884187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#-------------------------- Config.py --------------------------#\n",
    "class Config:\n",
    "#   TRAINSET_PATH = \"/kaggle/input/cs229train/Frames\"\n",
    "  TRAINSET_PATH = \"/kaggle/input/maxcs229train\"\n",
    "  SINGLE_TEST_PATH = \"/kaggle/input/wolvesmancity122719hg/WolvesManCity122719H/clip19\"\n",
    "  TESTSET_PATH = \"/kaggle/input/cs229test\"\n",
    "  BATCH_SIZE = 4\n",
    "  EPOCHS = 3\n",
    "  MODEL_PATH = \"/kaggle/input/model3vids\"\n",
    "  PLAY_LEN = 30#seconds\n",
    "  FPS = 2#frames per second\n",
    "  FPP = PLAY_LEN * FPS#frames per play\n",
    "  SEQ_LEN = 10#frames\n",
    "#-------------------------- Imports --------------------------#\n",
    "from os import listdir\n",
    "from os.path import isfile, join, isdir\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import shelve\n",
    "import cv2\n",
    "import keras\n",
    "from keras.layers import Conv2DTranspose, ConvLSTM2D, BatchNormalization, TimeDistributed, Conv2D\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LayerNormalization\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-15T12:13:35.207888Z",
     "iopub.status.busy": "2020-11-15T12:13:35.203893Z",
     "iopub.status.idle": "2020-11-15T12:13:35.210220Z",
     "shell.execute_reply": "2020-11-15T12:13:35.210680Z"
    },
    "papermill": {
     "duration": 0.037554,
     "end_time": "2020-11-15T12:13:35.210914",
     "exception": false,
     "start_time": "2020-11-15T12:13:35.173360",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#-------------------------- DataParsing.py --------------------------#\n",
    "from os import listdir\n",
    "from os.path import isfile, join, isdir\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import shelve\n",
    "import cv2\n",
    "def get_clips_by_stride(stride, frames_list, sequence_size):\n",
    "    \"\"\" For data augmenting purposes.\n",
    "    Parameters\n",
    "    ----------\n",
    "    stride : int\n",
    "        The desired distance between two consecutive frames\n",
    "    frames_list : list\n",
    "        A list of sorted frames of shape 256 X 256\n",
    "    sequence_size: int\n",
    "        The size of the desired LSTM sequence\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        A list of clips , 10 frames each\n",
    "    \"\"\"\n",
    "    clips = []\n",
    "    sz = len(frames_list)\n",
    "    clip = np.zeros(shape=(sequence_size, 256, 256, 1))\n",
    "    cnt = 0\n",
    "    for start in range(0, stride):\n",
    "        for i in range(start, sz, stride):\n",
    "            clip[cnt, :, :, 0] = frames_list[i]\n",
    "            cnt = cnt + 1\n",
    "            if cnt == sequence_size:\n",
    "                clips.append(np.copy(clip))\n",
    "                cnt = 0\n",
    "    return clips\n",
    "\n",
    "def get_training_set():\n",
    "    \"\"\"\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        A list of training sequences of shape (NUMBER_OF_SEQUENCES,SINGLE_SEQUENCE_SIZE,FRAME_WIDTH,FRAME_HEIGHT,1)\n",
    "    \"\"\"\n",
    "    #####################################\n",
    "    # cache = shelve.open(Config.CACHE_PATH)\n",
    "    # return cache[\"datasetLSTM\"]\n",
    "    #####################################\n",
    "    clips = []\n",
    "    # loop over the training folders (Train000,Train001,..)\n",
    "    print('Found %d games' %len(listdir(Config.TRAINSET_PATH)))\n",
    "    for game in sorted(listdir(Config.TRAINSET_PATH))[:7]:\n",
    "        if \"New\" in game or \"Ars\" in game or \"Eve\" in game:\n",
    "            continue\n",
    "        print('found %d clips for %s' %(len(listdir(join(Config.TRAINSET_PATH, game))), game))\n",
    "        all_frames = []\n",
    "        for clip in sorted(listdir(join(Config.TRAINSET_PATH, game))):\n",
    "            if isdir(join(Config.TRAINSET_PATH, game, clip)):\n",
    "#                 all_frames = []\n",
    "                # loop over all the images in the folder (0.tif,1.tif,..,199.tif)\n",
    "                for frame in sorted(listdir(join(Config.TRAINSET_PATH, game, clip))):\n",
    "                    if str(join(Config.TRAINSET_PATH, game, clip, frame))[-3:] == \"tif\":\n",
    "                        img = Image.open(join(Config.TRAINSET_PATH, game, clip, frame)).resize((256, 256))\n",
    "                        img = np.array(img, dtype=np.float32) / 256.0\n",
    "                        all_frames.append(img)\n",
    "                        \n",
    "        # get the SEQ_LEN sequences from the list of images after applying data augmentation\n",
    "        for stride in range(1, 3):\n",
    "            print('all_frames.shape: ', np.array(all_frames).shape)\n",
    "            clips.extend(get_clips_by_stride(stride=stride, frames_list=all_frames, sequence_size=Config.SEQ_LEN))\n",
    "#             print('clips.shape: ', np.array(clips).shape)\n",
    "            input()\n",
    "    return clips\n",
    "#----------------------------- Parse Data From Max DB ----------------------------#\n",
    "def get_max_training_set():\n",
    "    \"\"\"\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        A list of training sequences of shape (NUMBER_OF_SEQUENCES,SINGLE_SEQUENCE_SIZE,FRAME_WIDTH,FRAME_HEIGHT,1)\n",
    "    \"\"\"\n",
    "    #####################################\n",
    "    # cache = shelve.open(Config.CACHE_PATH)\n",
    "    # return cache[\"datasetLSTM\"]\n",
    "    #####################################\n",
    "    clips = []\n",
    "    # loop over the training folders (Train000,Train001,..)\n",
    "    print('Found %d games' %len(listdir(Config.TRAINSET_PATH)))\n",
    "    for game in sorted(listdir(Config.TRAINSET_PATH))[:3]:\n",
    "        all_frames = np.load(join(Config.TRAINSET_PATH, game))\n",
    "        print(\"loaded shape: \", all_frames.shape)\n",
    "        print(\"reshaped shape: \", all_frames.reshape(-1, 256, 256).shape)\n",
    "        all_frames = all_frames.reshape(-1, 256, 256)\n",
    "        print(\"Loaded \", game)\n",
    "        # get the SEQ_LEN sequences from the list of images after applying data augmentation\n",
    "        for stride in range(1, 3):\n",
    "#             print('all_frames.shape: ', np.array(all_frames).shape)\n",
    "            clips.extend(get_clips_by_stride(stride=stride, frames_list=all_frames, sequence_size=Config.SEQ_LEN))\n",
    "#             print('clips.shape: ', np.array(clips).shape)\n",
    "#             input()\n",
    "    return clips\n",
    "# get_max_training_set()\n",
    "# get_training_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-15T12:13:35.257745Z",
     "iopub.status.busy": "2020-11-15T12:13:35.255764Z",
     "iopub.status.idle": "2020-11-15T12:13:35.258416Z",
     "shell.execute_reply": "2020-11-15T12:13:35.258899Z"
    },
    "papermill": {
     "duration": 0.041187,
     "end_time": "2020-11-15T12:13:35.259040",
     "exception": false,
     "start_time": "2020-11-15T12:13:35.217853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#-------------------------- UnsupervisedModels.py --------------------------#\n",
    "import keras\n",
    "from keras.layers import Conv2DTranspose, ConvLSTM2D, BatchNormalization, TimeDistributed, Conv2D\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LayerNormalization\n",
    "def get_lstm_model(reload_model=True):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    reload_model : bool\n",
    "        Load saved model or retrain it\n",
    "    \"\"\"\n",
    "    if not reload_model:\n",
    "        return load_model(Config.MODEL_PATH,custom_objects={'LayerNormalization': LayerNormalization})\n",
    "#     training_set = get_training_set()\n",
    "    training_set = get_max_training_set()\n",
    "    training_set = np.array(training_set)\n",
    "    print('training_set.shape: ', training_set.shape)\n",
    "    training_set = training_set.reshape(-1,Config.SEQ_LEN,256,256,1)\n",
    "    print('training_set.shape after reshape: ', training_set.shape)\n",
    "    seq = Sequential()\n",
    "    seq.add(TimeDistributed(Conv2D(128, (11, 11), strides=4, padding=\"same\"), batch_input_shape=(None, Config.SEQ_LEN, 256, 256, 1)))\n",
    "    seq.add(LayerNormalization())\n",
    "    seq.add(TimeDistributed(Conv2D(64, (5, 5), strides=2, padding=\"same\")))\n",
    "    seq.add(LayerNormalization())\n",
    "    # # # # #\n",
    "    seq.add(ConvLSTM2D(64, (3, 3), padding=\"same\", return_sequences=True))\n",
    "    seq.add(LayerNormalization())\n",
    "    seq.add(ConvLSTM2D(32, (3, 3), padding=\"same\", return_sequences=True))\n",
    "    seq.add(LayerNormalization())\n",
    "    seq.add(ConvLSTM2D(64, (3, 3), padding=\"same\", return_sequences=True))\n",
    "    seq.add(LayerNormalization())\n",
    "    # # # # #\n",
    "    seq.add(TimeDistributed(Conv2DTranspose(64, (5, 5), strides=2, padding=\"same\")))\n",
    "    seq.add(LayerNormalization())\n",
    "    seq.add(TimeDistributed(Conv2DTranspose(128, (11, 11), strides=4, padding=\"same\")))\n",
    "    seq.add(LayerNormalization())\n",
    "    seq.add(TimeDistributed(Conv2D(1, (11, 11), activation=\"sigmoid\", padding=\"same\")))\n",
    "    print(seq.summary())\n",
    "    seq.compile(loss='mse', optimizer=keras.optimizers.Adam(lr=1e-4, decay=1e-5, epsilon=1e-6))\n",
    "    seq.fit(training_set, training_set,\n",
    "            batch_size=Config.BATCH_SIZE, epochs=Config.EPOCHS, shuffle=False)\n",
    "    seq.save(Config.MODEL_PATH)\n",
    "    return seq\n",
    "\n",
    "def get_single_test(test_clip):\n",
    "    test = np.zeros(shape=(Config.FPP, 256, 256, 1))\n",
    "    cnt = 0\n",
    "    for f in sorted(listdir(join(Config.TESTSET_PATH, test_clip))):\n",
    "        if cnt == Config.FPP:\n",
    "            break\n",
    "        if str(join(join(Config.TESTSET_PATH, test_clip), f))[-3:] == \"tif\":\n",
    "            img = Image.open(join(join(Config.TESTSET_PATH, test_clip), f)).resize((256, 256))\n",
    "            img = np.array(img, dtype=np.float32) / 256.0\n",
    "            test[cnt, :, :, 0] = img\n",
    "            cnt += 1\n",
    "\n",
    "    sz = test.shape[0] - Config.SEQ_LEN\n",
    "    sequences = np.zeros((sz, Config.SEQ_LEN, 256, 256, 1))\n",
    "    # apply the sliding window technique to get the sequences\n",
    "    for i in range(0, sz):\n",
    "        clip = np.zeros((Config.SEQ_LEN, 256, 256, 1))\n",
    "        for j in range(0, Config.SEQ_LEN):\n",
    "            clip[j] = test[i + j, :, :, :]\n",
    "        sequences[i] = clip\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-15T12:13:35.276837Z",
     "iopub.status.busy": "2020-11-15T12:13:35.276244Z",
     "iopub.status.idle": "2020-11-15T12:21:20.707735Z",
     "shell.execute_reply": "2020-11-15T12:21:20.708488Z"
    },
    "papermill": {
     "duration": 465.442853,
     "end_time": "2020-11-15T12:21:20.708642",
     "exception": false,
     "start_time": "2020-11-15T12:13:35.265789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19 games\n",
      "loaded shape:  (80, 10, 256, 256)\n",
      "reshaped shape:  (800, 256, 256)\n",
      "Loaded  0.npy\n",
      "loaded shape:  (80, 10, 256, 256)\n",
      "reshaped shape:  (800, 256, 256)\n",
      "Loaded  1.npy\n",
      "loaded shape:  (57, 10, 256, 256)\n",
      "reshaped shape:  (570, 256, 256)\n",
      "Loaded  10.npy\n",
      "training_set.shape:  (434, 10, 256, 256, 1)\n",
      "training_set.shape after reshape:  (434, 10, 256, 256, 1)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed (TimeDistri (None, 10, 64, 64, 128)   15616     \n",
      "_________________________________________________________________\n",
      "layer_normalization (LayerNo (None, 10, 64, 64, 128)   256       \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 10, 32, 32, 64)    204864    \n",
      "_________________________________________________________________\n",
      "layer_normalization_1 (Layer (None, 10, 32, 32, 64)    128       \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d (ConvLSTM2D)    (None, 10, 32, 32, 64)    295168    \n",
      "_________________________________________________________________\n",
      "layer_normalization_2 (Layer (None, 10, 32, 32, 64)    128       \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_1 (ConvLSTM2D)  (None, 10, 32, 32, 32)    110720    \n",
      "_________________________________________________________________\n",
      "layer_normalization_3 (Layer (None, 10, 32, 32, 32)    64        \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_2 (ConvLSTM2D)  (None, 10, 32, 32, 64)    221440    \n",
      "_________________________________________________________________\n",
      "layer_normalization_4 (Layer (None, 10, 32, 32, 64)    128       \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 10, 64, 64, 64)    102464    \n",
      "_________________________________________________________________\n",
      "layer_normalization_5 (Layer (None, 10, 64, 64, 64)    128       \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 10, 256, 256, 128) 991360    \n",
      "_________________________________________________________________\n",
      "layer_normalization_6 (Layer (None, 10, 256, 256, 128) 256       \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 10, 256, 256, 1)   15489     \n",
      "=================================================================\n",
      "Total params: 1,958,209\n",
      "Trainable params: 1,958,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      "109/109 [==============================] - 145s 1s/step - loss: 14907.9561\n",
      "Epoch 2/3\n",
      "109/109 [==============================] - 142s 1s/step - loss: 14905.2871\n",
      "Epoch 3/3\n",
      "109/109 [==============================] - 142s 1s/step - loss: 14905.2871\n"
     ]
    },
    {
     "ename": "PermissionDeniedError",
     "evalue": "/kaggle/input/model3vids/variables/variables_temp_0bb553d887a649bda0f9e036736f1874; Read-only file system [Op:SaveV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionDeniedError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-2e07d2f58417>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_lstm_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"saved model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-6f474f9a3d7a>\u001b[0m in \u001b[0;36mget_lstm_model\u001b[0;34m(reload_model)\u001b[0m\n\u001b[1;32m     41\u001b[0m     seq.fit(training_set, training_set,\n\u001b[1;32m     42\u001b[0m             batch_size=Config.BATCH_SIZE, epochs=Config.EPOCHS, shuffle=False)\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[1;32m   1977\u001b[0m     \"\"\"\n\u001b[1;32m   1978\u001b[0m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[0;32m-> 1979\u001b[0;31m                     signatures, options)\n\u001b[0m\u001b[1;32m   1980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1981\u001b[0m   def save_weights(self,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[1;32m    132\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     saved_model_save.save(model, filepath, overwrite, include_optimizer,\n\u001b[0;32m--> 134\u001b[0;31m                           signatures, options)\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/save.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(model, filepath, overwrite, include_optimizer, signatures, options)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;31m# we use the default replica context here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mdistribution_strategy_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_default_replica_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m       \u001b[0msave_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, export_dir, signatures, options)\u001b[0m\n\u001b[1;32m    983\u001b[0m       experimental_io_device=options.experimental_io_device)\n\u001b[1;32m    984\u001b[0m   object_saver.save(utils_impl.get_variables_path(export_dir),\n\u001b[0;32m--> 985\u001b[0;31m                     options=ckpt_options)\n\u001b[0m\u001b[1;32m    986\u001b[0m   builder_impl.copy_assets_to_destination_dir(asset_info.asset_filename_map,\n\u001b[1;32m    987\u001b[0m                                               export_dir)\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, file_prefix, checkpoint_number, session, options)\u001b[0m\n\u001b[1;32m   1198\u001b[0m     \u001b[0mfile_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecursive_create_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m     save_path, new_feed_additions = self._save_cached_when_graph_building(\n\u001b[0;32m-> 1200\u001b[0;31m         file_prefix_tensor, object_graph_tensor, options)\n\u001b[0m\u001b[1;32m   1201\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnew_feed_additions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m       \u001b[0mfeed_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_feed_additions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36m_save_cached_when_graph_building\u001b[0;34m(self, file_prefix, object_graph_tensor, options)\u001b[0m\n\u001b[1;32m   1143\u001b[0m         or context.executing_eagerly() or ops.inside_function()):\n\u001b[1;32m   1144\u001b[0m       \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctional_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultiDeviceSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnamed_saveable_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m       \u001b[0msave_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/cpu:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msave_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/saving/functional_saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, file_prefix, options)\u001b[0m\n\u001b[1;32m    293\u001b[0m       \u001b[0mtf_function_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msave_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/saving/functional_saver.py\u001b[0m in \u001b[0;36msave_fn\u001b[0;34m()\u001b[0m\n\u001b[1;32m    267\u001b[0m           \u001b[0;31m# initial read operations should be placed on the SaveableObject's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m           \u001b[0;31m# device.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m           \u001b[0msharded_saves\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshard_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msharded_saves\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/saving/functional_saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, file_prefix, options)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0msave_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_io_device\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"cpu:0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mio_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_slices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36msave_v2\u001b[0;34m(prefix, tensor_names, shape_and_slices, tensors, name)\u001b[0m\n\u001b[1;32m   1729\u001b[0m       return save_v2_eager_fallback(\n\u001b[1;32m   1730\u001b[0m           \u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_and_slices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1731\u001b[0;31m           ctx=_ctx)\n\u001b[0m\u001b[1;32m   1732\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1733\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36msave_v2_eager_fallback\u001b[0;34m(prefix, tensor_names, shape_and_slices, tensors, name, ctx)\u001b[0m\n\u001b[1;32m   1749\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"dtypes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_dtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1750\u001b[0m   _result = _execute.execute(b\"SaveV2\", 0, inputs=_inputs_flat, attrs=_attrs,\n\u001b[0;32m-> 1751\u001b[0;31m                              ctx=ctx, name=name)\n\u001b[0m\u001b[1;32m   1752\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPermissionDeniedError\u001b[0m: /kaggle/input/model3vids/variables/variables_temp_0bb553d887a649bda0f9e036736f1874; Read-only file system [Op:SaveV2]"
     ]
    }
   ],
   "source": [
    "#-------------------------- Train.py --------------------------#\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = get_lstm_model(True)\n",
    "print(\"saved model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-15T12:21:21.065284Z",
     "iopub.status.busy": "2020-11-15T12:21:21.063384Z",
     "iopub.status.idle": "2020-11-15T12:21:22.082746Z",
     "shell.execute_reply": "2020-11-15T12:21:22.084211Z"
    },
    "papermill": {
     "duration": 1.193278,
     "end_time": "2020-11-15T12:21:22.084414",
     "exception": false,
     "start_time": "2020-11-15T12:21:20.891136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on clip101\n",
      "got test - shape:  (50, 10, 256, 256, 1)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-0c7512ba341a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"got test - shape: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_sequences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# get the reconstruction cost of all the sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mreconstructed_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sequences\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0msequences_reconstruction_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreconstructed_sequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msequences_reconstruction_cost\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences_reconstruction_cost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences_reconstruction_cost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "#-------------------------- Predict.py --------------------------#\n",
    "test_clips = sorted(listdir(Config.TESTSET_PATH))\n",
    "# model = get_lstm_model(reload_model=False)\n",
    "#Test on NUM_TESTS randomly chosen clips from the testing set\n",
    "# test_clips = random.sample(test_clips, Config.NUM_TESTS)\n",
    "for test_clip in test_clips:\n",
    "    print(\"Testing on \" + test_clip)\n",
    "    if test_clip[0] == '.':\n",
    "        print(\"%s not a clip. Skipping...\" %test_clip)\n",
    "        continue\n",
    "    test_sequences = get_single_test(test_clip)\n",
    "    print(\"got test - shape: \", test_sequences.shape)\n",
    "    # get the reconstruction cost of all the sequences\n",
    "    reconstructed_sequences = model.predict(test_sequences,batch_size=4)\n",
    "    sequences_reconstruction_cost = np.array([np.linalg.norm(np.subtract(test_sequences[i],reconstructed_sequences[i])) for i in range(0,len(test_sequences))])\n",
    "    sa = (sequences_reconstruction_cost - np.min(sequences_reconstruction_cost)) / np.max(sequences_reconstruction_cost)\n",
    "    sr = 1.0 - sa\n",
    "\n",
    "    # plot the regularity scores\n",
    "    plt.figure()\n",
    "    plt.plot(sr)\n",
    "    plt.ylabel('regularity score Sr(t)')\n",
    "    plt.xlabel('frame t')\n",
    "    plt.savefig(test_clip +'.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.183826,
     "end_time": "2020-11-15T12:21:22.471388",
     "exception": false,
     "start_time": "2020-11-15T12:21:22.287562",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 483.115221,
   "end_time": "2020-11-15T12:21:24.403691",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-15T12:13:21.288470",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
